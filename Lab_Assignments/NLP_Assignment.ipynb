{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoOQH9Y8-Jnv"
   },
   "source": [
    "**NLP Assignment -- Text Preprocessing (example using a simple Naive Bayes classifier)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfUILpaL-UZL"
   },
   "source": [
    "**SUPRATIM NAG (CSE/22/057)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ie28z36jvbB4",
    "outputId": "867b74fa-8b0c-44cc-fbce-a05673918ac9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "wD8q7e34vzJt",
    "outputId": "af72ce1b-1125-4b1d-e9a9-9b620114eecf"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cEjVJfT881IK"
   },
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kIrmLeyx9JVV",
    "outputId": "05619186-e867-4c9b-9a2b-dd8532633da0"
   },
   "outputs": [],
   "source": [
    "# Initialize the lemmatizer and download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ycVhE8MB9OH3"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3RLZupqr9S6L"
   },
   "outputs": [],
   "source": [
    "# Training data (using a toy dataset for illustration purposes)\n",
    "training_data = [\n",
    "    (\"It was a great movie.\", \"pos\"),\n",
    "    (\"I hated the book.\", \"neg\"),\n",
    "    (\"The book was okay.\", \"pos\"),\n",
    "    (\"I absolutely loved the performance!\", \"pos\"),\n",
    "    (\"The plot was boring and predictable.\", \"neg\"),\n",
    "    (\"What an amazing experience!\", \"pos\"),\n",
    "    (\"The food was terrible.\", \"neg\"),\n",
    "    (\"I enjoyed every minute of it.\", \"pos\"),\n",
    "    (\"The service was really bad.\", \"neg\"),\n",
    "    (\"It was an unforgettable adventure!\", \"pos\"),\n",
    "    (\"I don't think I'll watch it again.\", \"neg\"),\n",
    "    (\"The soundtrack was beautiful.\", \"pos\"),\n",
    "    (\"I regret buying this product.\", \"neg\"),\n",
    "    (\"The view was breathtaking!\", \"pos\"),\n",
    "    (\"The story lacked depth.\", \"neg\"),\n",
    "    (\"I am so happy with my purchase.\", \"pos\"),\n",
    "    (\"The customer service was disappointing.\", \"neg\"),\n",
    "    (\"It was worth every penny.\", \"pos\"),\n",
    "    (\"The quality is not up to the mark.\", \"neg\"),\n",
    "    (\"I'm thrilled with the results!\", \"pos\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Q1sLx8Iv9WdO"
   },
   "outputs": [],
   "source": [
    "# Function to preprocess and extract features from text\n",
    "def extract_features(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove punctuation and stopwords, and apply lemmatization\n",
    "    features = {\n",
    "        lemmatizer.lemmatize(word): True\n",
    "        for word in tokens if word not in stop_words and word not in string.punctuation\n",
    "    }\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "i6aWmoM_9ZHW"
   },
   "outputs": [],
   "source": [
    "# Create a list of feature sets and labels\n",
    "feature_sets = [(extract_features(text), label) for (text, label) in training_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "f4SSh24V9bBx"
   },
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "classifier = NaiveBayesClassifier.train(feature_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4BxAdGgx9csX",
    "outputId": "a02e08dd-0ea8-4121-c3eb-7dcff10bdcf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: pos\n"
     ]
    }
   ],
   "source": [
    "# Test the classifier on a new example\n",
    "test_text = \"The movie was great.\"\n",
    "print(\"Sentiment:\", classifier.classify(extract_features(test_text)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
